{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch as th\n",
    "th.set_num_threads(1)\n",
    "import syft as sy\n",
    "from syft.grid.clients.data_centric_fl_client import DataCentricFLClient\n",
    "hook = sy.TorchHook(th)\n",
    "alice = DataCentricFLClient(hook, \"ws://localhost:7600\")\n",
    "bob = DataCentricFLClient(hook, \"ws://localhost:7601\")\n",
    "my_grid = sy.PrivateGridNetwork(alice,bob)\n",
    "payload = 1_000 # in Mo\n",
    "t = th.rand(1, int(payload * 10**6 / 4)) # 4 because torch float32 are encded over 4 bytes\n",
    "timer = time.time()\n",
    "t.send(alice)\n",
    "delay = time.time() - timer\n",
    "print('bandwidth', payload/delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(alice.ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.ws.send(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alice.ws.recv()\n",
    "import pyarrow as pa\n",
    "data = [\n",
    "\n",
    "    pa.array([1, 2, 3, 4]),\n",
    "\n",
    "    pa.array(['foo', 'bar', 'baz', None]),\n",
    "\n",
    "    pa.array([True, None, False, True])\n",
    "\n",
    "]\n",
    "batch = pa.record_batch(data, names=['f0', 'f1', 'f2'])\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sink = alice.ws\n",
    "# writer = pa.ipc.new_stream(sink, batch.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ast\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import pyarrow\n",
    "import pyarrow as pa\n",
    "import pyarrow.flight\n",
    "import pyarrow.csv as csv\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "class FlightServer(pyarrow.flight.FlightServerBase):\n",
    "    def __init__(self, host=\"localhost\", location=None,\n",
    "                 tls_certificates=None, verify_client=False,\n",
    "                 root_certificates=None, auth_handler=None):\n",
    "        super(FlightServer, self).__init__(\n",
    "            location, auth_handler, tls_certificates, verify_client,\n",
    "            root_certificates)\n",
    "        self.flights = {}\n",
    "        self.host = host\n",
    "        self.tls_certificates = tls_certificates\n",
    "\n",
    "    @classmethod\n",
    "    def descriptor_to_key(self, descriptor):\n",
    "        return (descriptor.descriptor_type.value, descriptor.command,\n",
    "                tuple(descriptor.path or tuple()))\n",
    "\n",
    "    def _make_flight_info(self, key, descriptor, table):\n",
    "        if self.tls_certificates:\n",
    "            location = pyarrow.flight.Location.for_grpc_tls(\n",
    "                self.host, self.port)\n",
    "        else:\n",
    "            location = pyarrow.flight.Location.for_grpc_tcp(\n",
    "                self.host, self.port)\n",
    "        endpoints = [pyarrow.flight.FlightEndpoint(repr(key), [location]), ]\n",
    "\n",
    "        mock_sink = pyarrow.MockOutputStream()\n",
    "        stream_writer = pyarrow.RecordBatchStreamWriter(\n",
    "            mock_sink, table.schema)\n",
    "        stream_writer.write_table(table)\n",
    "        stream_writer.close()\n",
    "        data_size = mock_sink.size()\n",
    "\n",
    "        return pyarrow.flight.FlightInfo(table.schema,\n",
    "                                         descriptor, endpoints,\n",
    "                                         table.num_rows, data_size)\n",
    "\n",
    "    def list_flights(self, context, criteria):\n",
    "        for key, table in self.flights.items():\n",
    "            if key[1] is not None:\n",
    "                descriptor = \\\n",
    "                    pyarrow.flight.FlightDescriptor.for_command(key[1])\n",
    "            else:\n",
    "                descriptor = pyarrow.flight.FlightDescriptor.for_path(*key[2])\n",
    "\n",
    "            yield self._make_flight_info(key, descriptor, table)\n",
    "\n",
    "    def get_flight_info(self, context, descriptor):\n",
    "        key = FlightServer.descriptor_to_key(descriptor)\n",
    "        if key in self.flights:\n",
    "            table = self.flights[key]\n",
    "            return self._make_flight_info(key, descriptor, table)\n",
    "        raise KeyError('Flight not found.')\n",
    "\n",
    "    def do_put(self, context, descriptor, reader, writer):\n",
    "        key = FlightServer.descriptor_to_key(descriptor)\n",
    "        t = time.time()\n",
    "        print(f\"Got a new key: {key}\")\n",
    "        \n",
    "        print(type(reader))\n",
    "\n",
    "#         table = reader.read_all()\n",
    "        record_batch = reader.read_chunk().data\n",
    "        # self.flights[key] = reader.read_all()\n",
    "        dl_time = time.time() - t\n",
    "        \n",
    "        print(f\"Original object received in {dl_time}:\")\n",
    "        t = time.time()\n",
    "#         print(table.to_batches()[0])\n",
    "        print(record_batch)\n",
    "        print(pa.deserialize(record_batch[0].buffers()[2]))\n",
    "\n",
    "        \n",
    "#         print(pa.deserialize(table.to_batches()[0][0].buffers()[2]))\n",
    "        \n",
    "#         print(f\"Deserialized in {time.time() - t}\")\n",
    "        \n",
    "#         record_batch = pa.RecordBatch.from_arrays([pa.array([pa.serialize(np.array([42])).to_buffer().to_pybytes()])], names=[\"\"])\n",
    "#         buf_response = pa.serialize(np.array([42])).to_buffer()\n",
    "        print(struct.pack('<i', 42))\n",
    "        print(type(struct.pack('<i', 42)))\n",
    "        writer.write(struct.pack('<i', 42))\n",
    "        print(\"Written response\")\n",
    "#         writer.write(buf_response)\n",
    "#         writer.close()\n",
    "        \n",
    "        \n",
    "#         print(\"Read all:\")\n",
    "        \n",
    "#         print(table)\n",
    "#         print(type(table))\n",
    "        \n",
    "#         b = table.to_batches()\n",
    "#         print(b)\n",
    "# #         print(table.to_pydict())\n",
    "#         print(b[0])\n",
    "#         print(b[0].column(0))\n",
    "#         c = b[0].column(0)\n",
    "#         print(pa.deserialize(c))\n",
    "        \n",
    "#         # print(self.flights[key])\n",
    "#         print(table.to_pandas())\n",
    "#         print(table.shape)\n",
    "#         print(f\"Time: {dl_time}\")\n",
    "        \n",
    "    def back_to_bin():\n",
    "        return\n",
    "\n",
    "\n",
    "    def do_get(self, context, ticket):\n",
    "        key = ast.literal_eval(ticket.ticket.decode())\n",
    "        if key not in self.flights:\n",
    "            return None\n",
    "        return pyarrow.flight.RecordBatchStream(self.flights[key])\n",
    "\n",
    "    def list_actions(self, context):\n",
    "        return [\n",
    "            (\"clear\", \"Clear the stored flights.\"),\n",
    "            (\"shutdown\", \"Shut down this server.\"),\n",
    "        ]\n",
    "\n",
    "    def do_action(self, context, action):\n",
    "        if action.type == \"clear\":\n",
    "            raise NotImplementedError(\n",
    "                \"{} is not implemented.\".format(action.type))\n",
    "        elif action.type == \"healthcheck\":\n",
    "            pass\n",
    "        elif action.type == \"shutdown\":\n",
    "            yield pyarrow.flight.Result(pyarrow.py_buffer(b'Shutdown!'))\n",
    "            # Shut down on background thread to avoid blocking current\n",
    "            # request\n",
    "            threading.Thread(target=self._shutdown).start()\n",
    "        else:\n",
    "            raise KeyError(\"Unknown action {!r}\".format(action.type))\n",
    "\n",
    "    def _shutdown(self):\n",
    "        \"\"\"Shut down after a delay.\"\"\"\n",
    "        print(\"Server is shutting down...\")\n",
    "        time.sleep(2)\n",
    "        self.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving on grpc+tcp://localhost:7604\n",
      "Got a new key: (2, b'feed_crypto_store_fssb', ())\n",
      "<class 'pyarrow._flight.MetadataRecordBatchReader'>\n",
      "Original object received in 0.0010600090026855469:\n",
      "pyarrow.RecordBatch\n",
      ": binary\n",
      "[[189  97 145 ... 101  36 110]]\n",
      "b'*\\x00\\x00\\x00'\n",
      "<class 'bytes'>\n",
      "Written response\n",
      "Got a new key: (2, b'feed_crypto_store_fssb', ())\n",
      "<class 'pyarrow._flight.MetadataRecordBatchReader'>\n",
      "Original object received in 0.0014543533325195312:\n",
      "pyarrow.RecordBatch\n",
      ": binary\n",
      "[[189  97 145 ... 101  36 110]]\n",
      "b'*\\x00\\x00\\x00'\n",
      "<class 'bytes'>\n",
      "Written response\n"
     ]
    }
   ],
   "source": [
    "tls_certificates = []\n",
    "scheme = \"grpc+tcp\"\n",
    "host=\"localhost\"\n",
    "port=\"7604\"\n",
    "\n",
    "location = \"{}://{}:{}\".format(scheme, host, port)\n",
    "\n",
    "server = FlightServer(host, location)\n",
    "\n",
    "print(\"Serving on\", location)\n",
    "server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ariann': conda)",
   "language": "python",
   "name": "python38564bitariannconda407a02cfdfe64cc2a67215b7d5297e73"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
